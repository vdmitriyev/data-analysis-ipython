{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About\n",
    "\n",
    "Classification of Star-Quasar with Naive Bayes.\n",
    "\n",
    "### Links\n",
    "\n",
    "* [Python Scripts For Data](https://github.com/astroML/sklearn_tutorial/tree/master/doc/data/sdss_photoz)\n",
    "* Original Articles\n",
    "    - [Notebook](http://nbviewer.ipython.org/url/astroml.github.com/sklearn_tutorial/_downloads/08_regression_example.ipynb)\n",
    "    - [Detailed Description](http://www.astroml.org/sklearn_tutorial/regression.html)\n",
    "\n",
    "### Dependecies\n",
    "\n",
    "```\n",
    "pip install sklearn\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading data from http://www.astro.washington.edu/users/vanderplas/pydata/sdss_photoz.npy\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This file fetches photometric observations associated with SDSS galaxy\n",
    "spectra which have spectroscopically confirmed redshifts.  This directly\n",
    "queries the SDSS database for the information, and thus can take a few\n",
    "minutes to run.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import urllib, urllib2\n",
    "import numpy as np\n",
    "\n",
    "# Here's how the data can be downloaded directly from the SDSS server.\n",
    "# This route is limited to N = 50000, so we've done this separately\n",
    "def fetch_data_sql(N = 50000):\n",
    "    URL = 'http://cas.sdss.org/public/en/tools/search/x_sql.asp'\n",
    "    archive_file = 'sdss_galaxy_colors.npy'\n",
    "\n",
    "    dtype = [('mags', '5float32'),\n",
    "             ('specClass', 'int8'),\n",
    "             ('z', 'float32'),\n",
    "             ('zerr', 'float32')]\n",
    "\n",
    "    def sql_query(sql_str, url=URL, format='csv'):\n",
    "        \"\"\"Execute SQL query\"\"\"\n",
    "        # remove comments from string\n",
    "        sql_str = ' \\n'.join(map(lambda x: x.split('--')[0],\n",
    "                                 sql_str.split('\\n')))\n",
    "        params = urllib.urlencode(dict(cmd=sql_str, format=format))\n",
    "        return urllib.urlopen(url + '?%s' % params)\n",
    "\n",
    "    query_text = ('\\n'.join(\n",
    "            (\"SELECT TOP %i\" % N,\n",
    "             \"   modelMag_u, modelMag_g, modelMag_r, modelMag_i, modelMag_z, specClass, z, zErr\",\n",
    "             \"FROM SpecPhoto\",\n",
    "             \"WHERE \",\n",
    "             \"   modelMag_u BETWEEN 0 AND 19.6\",\n",
    "             \"   AND modelMag_g BETWEEN 0 AND 20\",\n",
    "             \"   AND zerr BETWEEN 0 and 0.03\",\n",
    "             \"   AND specClass > 1 -- not UNKNOWN or STAR\",\n",
    "             \"   AND specClass <> 5 -- not SKY\",\n",
    "             \"   AND specClass <> 6 -- not STAR_LATE\")))\n",
    "\n",
    "\n",
    "    if not os.path.exists(archive_file):\n",
    "        print \"querying for %i objects\" % N\n",
    "        print query_text\n",
    "        output = sql_query(query_text)\n",
    "        print \"finished.  Processing & saving data\"\n",
    "        try:\n",
    "            data = np.loadtxt(output, delimiter=',', skiprows=1, dtype=DTYPE)\n",
    "        except:\n",
    "            raise ValueError(output.read())\n",
    "        np.save(archive_file, data)\n",
    "    else:\n",
    "        print \"data already on disk\"\n",
    "\n",
    "\n",
    "DATA_URL = ('http://www.astro.washington.edu/users/'\n",
    "            'vanderplas/pydata/sdss_photoz.npy')\n",
    "LOCAL_FILE = 'sdss_photoz.npy'\n",
    "FOLDER = 'data/'\n",
    "\n",
    "# data directory is password protected so the public can't access it    \n",
    "password_mgr = urllib2.HTTPPasswordMgrWithDefaultRealm()\n",
    "password_mgr.add_password(None, DATA_URL, 'pydata', 'astroML')\n",
    "handler = urllib2.HTTPBasicAuthHandler(password_mgr)\n",
    "opener = urllib2.build_opener(handler)\n",
    "\n",
    "# download training data\n",
    "if not os.path.exists(FOLDER + LOCAL_FILE):\n",
    "    print \"downloading data from\", DATA_URL\n",
    "    fhandle = opener.open(DATA_URL)\n",
    "    open(FOLDER + LOCAL_FILE, 'wb').write(fhandle.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.load('data/sdss_photoz.npy')\n",
    "\n",
    "N = len(data)\n",
    "X = np.zeros((N, 4))\n",
    "X[:, 0] = data['u'] - data['g']\n",
    "X[:, 1] = data['g'] - data['r']\n",
    "X[:, 2] = data['r'] - data['i']\n",
    "X[:, 3] = data['i'] - data['z']\n",
    "z = data['redshift']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.13839722  0.61042595  0.27867508  0.34679604]\n",
      " [ 1.51262856  0.64428329  0.27687073  0.15073967]\n",
      " [ 1.64493179  0.83510208  0.46151543  0.41690731]\n",
      " ..., \n",
      " [ 1.77320099  0.74706268  0.30396843  0.24538612]\n",
      " [ 1.48406982  0.72762299  0.44620895  0.2953701 ]\n",
      " [ 1.72066689  0.81639671  0.40833282  0.32231903]]\n",
      "[ 0.0800357  0.0215853  0.0366892 ...,  0.121951   0.0607102  0.0433055]\n"
     ]
    }
   ],
   "source": [
    "Ntrain = 3 * N / 4\n",
    "Xtrain = X[:Ntrain]\n",
    "ztrain = z[:Ntrain]\n",
    "Xtest = X[Ntrain:]\n",
    "ztest = z[Ntrain:]\n",
    "\n",
    "print Xtrain\n",
    "print ztrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting Data\n",
    "\n",
    "DecisionTreeRegressor method implementation from scikit-learn will be used to train a model and predict redshifts for the test set based on a 20-level decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "clf = DecisionTreeRegressor()\n",
    "clf.fit(Xtrain, ztrain)\n",
    "zpred = clf.predict(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Accuracy\n",
    "\n",
    "One of the metric to measure accuracy is [RMSE - root-mean-square error ](https://en.wikipedia.org/wiki/Root-mean-square_deviation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.235104463352\n"
     ]
    }
   ],
   "source": [
    "rmse = np.sqrt(np.mean((ztest - zpred) ** 2))\n",
    "print 'RMSE: {0}'.format(rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
